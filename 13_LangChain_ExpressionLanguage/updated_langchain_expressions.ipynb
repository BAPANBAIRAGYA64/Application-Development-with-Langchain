{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain Expression Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me about the nutritional value of {input}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Pizza is a popular dish that originated in Italy but is now enjoyed worldwide. Its nutritional value can vary depending on the ingredients used and the size of the portion consumed. Here is a general overview:\\n\\n1. Calories: The calorie content of pizza can range significantly depending on the crust, toppings, and size. On average, a slice of cheese pizza (approximately 1/8th of a 14-inch pizza) contains about 200-300 calories. However, this can increase significantly with additional toppings like meat or extra cheese.\\n\\n2. Carbohydrates: Pizza is typically made with a dough crust, which is a significant source of carbohydrates. Carbohydrates provide energy to the body. The specific amount can vary depending on the crust thickness and size, but a slice of cheese pizza can contain around 25-35 grams of carbohydrates.\\n\\n3. Protein: The protein content of pizza can vary depending on the toppings. Cheese and meat toppings like pepperoni or sausage contribute to the protein content. A slice of cheese pizza can contain approximately 7-10 grams of protein.\\n\\n4. Fat: Pizza can be a significant source of fat, especially due to the cheese and meat toppings. The fat content can vary depending on the type and amount of cheese used. A slice of cheese pizza can contain about 8-12 grams of fat.\\n\\n5. Vitamins and Minerals: Pizza can provide some essential vitamins and minerals, but the amounts may be relatively low compared to other nutrient-dense foods. The exact nutritional profile depends on the toppings used. Tomatoes, often used in pizza sauce, contain vitamin C, vitamin A, and lycopene. Some pizzas can also include vegetables like onions, bell peppers, or mushrooms, which contribute additional vitamins and minerals.\\n\\nIt's important to note that while pizza can be enjoyed as part of a balanced diet, certain factors like excessive portion sizes, high-fat toppings, or a lack of vegetable toppings can contribute to a less healthy nutritional profile. Moderation and mindful ingredient choices are key to enjoying pizza as part of a healthy eating plan.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "chain.predict(input=\"Pizza\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Spaghetti is a type of pasta made from wheat flour and water. It is commonly served with various sauces, vegetables, and meats. The nutritional value of spaghetti can vary depending on the serving size and the ingredients used.\\n\\nHere is the approximate nutritional value of 1 cup (140 grams) of cooked spaghetti without added sauce:\\n\\nCalories: 220\\nCarbohydrates: 43 grams\\nProtein: 8 grams\\nFat: 1.3 grams\\nFiber: 2.5 grams\\nSugar: 0.9 grams\\nSodium: 1 milligram\\n\\nSpaghetti is a good source of energy due to its high carbohydrate content. It also provides a moderate amount of protein, which is essential for muscle growth and repair. However, spaghetti is not a significant source of fat.\\n\\nThe fiber content in spaghetti is relatively low, but it still contributes to digestive health and can help maintain a feeling of fullness. Additionally, spaghetti is low in sugar and sodium, which is beneficial for those monitoring their intake of these nutrients.\\n\\nIt's important to note that the nutritional value of spaghetti can change depending on the type of pasta used. Whole wheat spaghetti, for example, contains more fiber and nutrients compared to refined wheat spaghetti. Additionally, the nutritional value can significantly change if you add sauces, cheeses, or other ingredients to your spaghetti dish.\\n\\nOverall, while spaghetti can be a part of a balanced diet, it is essential to consider portion sizes and the overall nutritional composition of your meal to ensure a well-rounded and healthy diet.\")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "chain.invoke({\"input\": \"Spaghetti\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'input': {'title': 'Input', 'type': 'string'}}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ChainInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'input': {'title': 'Input'}}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Lasagna is a traditional Italian dish that consists of layers of pasta, meat or vegetable fillings, cheese, and tomato sauce. The specific nutritional value of lasagna can vary depending on the ingredients used, portion sizes, and cooking methods. However, here is a general overview of the nutritional components of a typical serving of lasagna:\\n\\n1. Carbohydrates: The primary source of carbohydrates in lasagna comes from the pasta. A typical serving of lasagna (approximately 1 cup) contains around 40-45 grams of carbohydrates. The pasta provides energy in the form of complex carbohydrates.\\n\\n2. Protein: The protein content of lasagna largely depends on the filling used. Traditional meat lasagna contains ground beef or Italian sausage, which contributes to its protein content. Vegetarian or vegetable lasagna may include plant-based protein sources like tofu or legumes. On average, a serving of lasagna provides around 15-20 grams of protein.\\n\\n3. Fat: The fat content of lasagna primarily comes from the cheese and any added oil or butter. The amount of fat can vary depending on the type and quantity of cheese used. A typical serving of lasagna can contain approximately 10-15 grams of fat.\\n\\n4. Fiber: The presence of vegetables and whole wheat pasta in some variations of lasagna can contribute to the dietary fiber content. Fiber aids in digestion, promotes satiety, and can help regulate blood sugar levels. On average, a serving of lasagna may provide around 5 grams of dietary fiber.\\n\\n5. Vitamins and minerals: Lasagna can offer various essential vitamins and minerals, depending on the ingredients used. Tomatoes, which are a common component of lasagna sauce, are a good source of vitamin C, potassium, and lycopene. Vegetables like spinach or bell peppers can contribute vitamins A and K, while cheese provides calcium and vitamin D.\\n\\nIt's worth noting that the nutritional value can vary significantly depending on the specific recipe and ingredients used. Additionally, portion sizes can greatly impact the overall nutritional intake. It's always recommended to consider the overall balance of your diet and consume lasagna in moderation as part of a varied and balanced eating plan.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | StrOutputParser()\n",
    "chain.invoke({\"input\": \"Lasagna\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"tell me 5 jokes about {input}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm.bind(stop=[\"\\n\"]) | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pizzas can vary widely in terms of their nutritional value depending on the ingredients used and the size of the portion consumed. Here is a general breakdown of the nutritional components typically found in a pizza:'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"pizzas\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPENAI Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"joke\",\n",
    "      \"description\": \"A joke\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"setup\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The setup for the joke\"\n",
    "          },\n",
    "          \"punchline\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The punchline for the joke\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"setup\", \"punchline\"]\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "chain = (\n",
    "    prompt\n",
    "    | llm.bind(function_call={\"name\": \"joke\"}, functions= functions)\n",
    "    | JsonOutputFunctionsParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why don't bears have fast food restaurants?\",\n",
       " 'punchline': \"Because they can't catch the delivery truck!\"}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input={\"input\": \"bears\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "\n",
    "vectorstore = Chroma.from_texts([\"Cats are typically 9.1 kg in weight.\",\n",
    "                                 \"Cats have retractable claws.\",\n",
    "                                 \"A group of cats is called a clowder.\",\n",
    "                                 \"Cats can rotate their ears 180 degrees.\",\n",
    "                                 \"The world's oldest cat lived to be 38 years old.\"],\n",
    "                                embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The oldest cat lived to be 38 years old.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"how old is the oldest cat?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = {\"bla\": \"test\", \"x\": \"hi\"}\n",
    "itemgetter(\"bla\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bla = itemgetter(\"bla\")\n",
    "get_bla(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer in the following language: {language}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = {\n",
    "    \"context\": itemgetter(\"question\") | retriever,\n",
    "    \"question\": itemgetter(\"question\"),\n",
    "    \"language\": itemgetter(\"language\")\n",
    "} | prompt | llm | StrOutputParser()\n",
    "\n",
    "# chain = {\n",
    "#     \"context\": (lambda x: x[\"question\"]) | retriever,\n",
    "#     \"question\": (lambda x: x[\"question\"]),\n",
    "#     \"language\": (lambda x: x[\"language\"])\n",
    "# } | prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"question\": \"how old is the oldest cat?\", \"language\": \"german\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "search = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"turn the following user input into a search query for a search engine:\n",
    "\n",
    "{input}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | StrOutputParser() | search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"input\": \"whats the name of the oldest cat?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbitrary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "def length_function(text):\n",
    "    return len(text)\n",
    "\n",
    "def _multiple_length_function(text1, text2):\n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "def multiple_length_function(_dict):\n",
    "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"what is {a} + {b}\")\n",
    "\n",
    "chain = {\n",
    "    \"a\": itemgetter(\"foo\") | RunnableLambda(length_function),\n",
    "    \"b\": {\"text1\": itemgetter(\"foo\"), \"text2\": itemgetter(\"bar\")} | RunnableLambda(multiple_length_function)\n",
    "} | prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"foo\": \"bar\", \"bar\": \"gah\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in chain.stream({\"topic\": \"bears\"}):\n",
    "    print(s.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.batch([{\"topic\": \"bears\"}, {\"topic\": \"cats\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async for s in chain.astream({\"topic\": \"bears\"}):\n",
    "    print(s.content, end=\"\")\n",
    "await chain.ainvoke({\"topic\": \"bears\"})\n",
    "await chain.abatch([{\"topic\": \"bears\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableParallel\n",
    "chain1 = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\") | model\n",
    "chain2 = ChatPromptTemplate.from_template(\"tell me a bad joke about {topic}\") | model\n",
    "combined = RunnableParallel(joke=chain1, poem=chain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain2.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fallbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a funny comedian and provide funny jokes about specific topics\"),\n",
    "        (\"human\", \"Make a joke about {input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "fallback_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You tell the user that you currently are not able to make jokes since you are too tired\"),\n",
    "        (\"human\", \"Make a joke about {input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "bad_llm = ChatOpenAI(model_name=\"gpt-fake\")\n",
    "bad_chain = chat_prompt | bad_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()\n",
    "good_chain = fallback_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = bad_chain.with_fallbacks([good_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"input\": \"cow\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
